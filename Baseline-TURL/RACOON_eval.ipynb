{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "import tqdm\n",
    "from utils import *\n",
    "from type_vocabs import *\n",
    "import tiktoken\n",
    "enc = tiktoken.encoding_for_model(\"gpt-3.5-turbo-0125\")\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize(types):\n",
    "    cnt = 0\n",
    "    result = {}\n",
    "    for type in type_vocab:\n",
    "        result[type] = 0\n",
    "    for item in types:\n",
    "        if item in result:\n",
    "            result[item] = 1\n",
    "        else: \n",
    "            cnt += 1\n",
    "\n",
    "    return result, cnt\n",
    "\n",
    "def f1_score_multilabel(true_list, pred_list, types_label=None):\n",
    "    if types_label is not None:\n",
    "        conf_mat = multilabel_confusion_matrix(np.array(true_list),\n",
    "                                           np.array(pred_list),labels=types_label)\n",
    "    else: conf_mat = multilabel_confusion_matrix(np.array(true_list),\n",
    "                                           np.array(pred_list))\n",
    "    agg_conf_mat = conf_mat.sum(axis=0)\n",
    "    # Note: Pos F1\n",
    "    # [[TN FP], [FN, TP]] if we consider 1 as the positive class\n",
    "    p = agg_conf_mat[1, 1] / agg_conf_mat[1, :].sum()\n",
    "    r = agg_conf_mat[1, 1] / agg_conf_mat[:, 1].sum()\n",
    "    \n",
    "    micro_f1 = 2 * p * r / (p  + r) if (p + r) > 0 else 0.\n",
    "    class_p = conf_mat[:, 1, 1] /  conf_mat[:, 1, :].sum(axis=1)\n",
    "    class_r = conf_mat[:, 1, 1] /  conf_mat[:, :, 1].sum(axis=1)\n",
    "    class_f1 = np.divide(2 * (class_p * class_r), class_p + class_r,\n",
    "                         out=np.zeros_like(class_p), where=(class_p + class_r) != 0)\n",
    "    class_f1 = np.nan_to_num(class_f1)\n",
    "    macro_f1 = class_f1.mean()\n",
    "    return (micro_f1, macro_f1, class_f1, conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sotab_eval(data_dir, labels, type_vocab, col_pairs=None, is_triplet=False, correct=False):\n",
    "    preds = []\n",
    "    ground_truth = []\n",
    "    num_oov = 0\n",
    "    hints = []\n",
    "    with open(data_dir, mode ='r') as file:\n",
    "        csvFile = csv.reader(file)\n",
    "        for id, lines in enumerate(csvFile):\n",
    "                num = lines[0]\n",
    "                idx = lines[1]\n",
    "                label = labels[id]\n",
    "                ground_truth.append(str(label))\n",
    "                hint = \"\"\n",
    "                if len(lines) <= 2:\n",
    "                    preds.append(\"\")\n",
    "                    hints.append(\"\")\n",
    "                    continue\n",
    "                if len(lines) >= 4:\n",
    "                    hint = lines[3]\n",
    "                # if hint is not None and is_triplet: \n",
    "                #     hint = hint.split(\":\", 1)[1].strip()\n",
    "                hints.append(hint)\n",
    "                \n",
    "                try:\n",
    "                    data = json.loads(lines[2].replace(\"'\", '\"'))\n",
    "                    type_value = data.get('relation', [])\n",
    "                    if isinstance(type_value, list) and len(type_value) > 0:\n",
    "                        type_value = type_value[0]\n",
    "                    preds.append(str(type_value))\n",
    "                    if type_value not in type_vocab:\n",
    "                        num_oov += 1\n",
    "                    if not correct and type_value != label:\n",
    "                        col_pairs.append((num,idx,type_value,label,hint))\n",
    "                    if correct and type_value == label:\n",
    "                        col_pairs.append((num,idx,type_value,label,hint))\n",
    "                except json.JSONDecodeError:\n",
    "                    preds.append(\"\")\n",
    "                    print(f\"Error decoding JSON in line: {lines}\")\n",
    "    print(\"len(preds): \", len(preds))\n",
    "    micro_f1, macro_f1, class_f1, conf_mat = f1_score_multilabel(ground_truth, preds, type_vocab)\n",
    "    return micro_f1, macro_f1, class_f1, conf_mat, num_oov, hints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_label_eval(data_dir, labels, wrong_col_pairs = None, decode_ok=0):\n",
    "    preds = []\n",
    "    ground_truth = []\n",
    "    empty = serialize([])[0].values()\n",
    "    empty = [*empty]\n",
    "    num_oov = 0\n",
    "    with open(data_dir, mode ='r') as file:\n",
    "        csvFile = csv.reader(file)\n",
    "        for id, lines in enumerate(csvFile):\n",
    "                pred = []\n",
    "                if len(lines) <= 2:\n",
    "                    preds.append(empty)\n",
    "                    continue\n",
    "                try:\n",
    "                    num = lines[0]\n",
    "                    idx = lines[1]\n",
    "                    data = json.loads(lines[2].replace(\"'\", '\"'))\n",
    "                    type_value = data.get('type', [])\n",
    "                    label = labels[id]\n",
    "                    pred_dic, cnt = serialize(type_value)\n",
    "                    num_oov += cnt\n",
    "                    pred = pred_dic.values()\n",
    "                    pred = [*pred]\n",
    "                    preds.append(pred)\n",
    "                    decode_ok += 1\n",
    "                    if len(type_value) > 0 and type_value[0] in label:\n",
    "                        gt = pred\n",
    "                    else:\n",
    "                        gt = serialize(label)[0].values()\n",
    "                        gt = [*gt]\n",
    "                        if wrong_col_pairs is not None: \n",
    "                            wrong_col_pairs.append((num,idx,type_value ,label))\n",
    "\n",
    "                except json.JSONDecodeError:\n",
    "                    \n",
    "                    preds.append(empty)\n",
    "                    label = labels[id]\n",
    "                    gt = serialize(label)[0].values()\n",
    "                    gt = [*gt]\n",
    "                    print(f\"Error decoding JSON in line: {lines}\")\n",
    "                ground_truth.append(gt)\n",
    "    print(\"len(preds): \", len(preds))\n",
    "    micro_f1, macro_f1, class_f1, conf_mat = f1_score_multilabel(ground_truth, preds)\n",
    "    return micro_f1, macro_f1, class_f1, conf_mat, num_oov, decode_ok\n",
    "\n",
    "def multi_label_eval(data_dir, labels):\n",
    "    ground_truth = []\n",
    "    for label in labels:\n",
    "        label = ast.literal_eval(label)\n",
    "        gt = serialize(label).values()\n",
    "        gt = [*gt]\n",
    "        ground_truth.append(gt)\n",
    "    preds = []\n",
    "    empty = serialize([])[0].values()\n",
    "    empty = [*empty]\n",
    "    with open(data_dir, mode ='r') as file:\n",
    "        csvFile = csv.reader(file)\n",
    "        for lines in csvFile:\n",
    "                pred = []\n",
    "                if len(lines) <= 2:\n",
    "                    preds.append(empty)\n",
    "                    continue\n",
    "                try:\n",
    "                    data = json.loads(lines[2].replace(\"'\", '\"'))\n",
    "                    type_value = data.get('type', [])\n",
    "                    pred = serialize(type_value).values()\n",
    "                    pred = [*pred]\n",
    "                    preds.append(pred)\n",
    "                except json.JSONDecodeError:\n",
    "                    preds.append(empty)\n",
    "    \n",
    "    micro_f1, macro_f1, class_f1, conf_mat = f1_score_multilabel(ground_truth, preds)\n",
    "    return micro_f1, macro_f1, class_f1, conf_mat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error decoding JSON in line: ['149', '0', '```json\\n{\\n    \"type\": [\"location.citytown\"]\\n}\\n```', \"['Henbury', 'Clifton', 'Cotham', 'Clifton', 'Fishponds']\"]\n",
      "Error decoding JSON in line: ['149', '1', '```json\\n{\\n    \"type\": [\"location.city\"]\\n}\\n```', \"['Bristol', 'Somerset', 'Bristol', 'Bristol', 'Bristol']\"]\n",
      "Error decoding JSON in line: ['362', '0', '```json\\n{\\n    \"type\": [\\n        \"book.periodical_subject\"\\n    ]\\n}\\n```', \"['abdominal aortic aneurysm', 'Athletics Australia', 'year', 'year', 'year']\"]\n",
      "Error decoding JSON in line: ['362', '1', '```json\\n{\\n    \"type\": [\\n        \"basketball.basketball_team\"\\n    ]\\n}\\n```', '[]']\n",
      "Error decoding JSON in line: ['362', '2', '```json\\n{\\n    \"type\": [\\n        \"military.military_person\"\\n    ]\\n}\\n```', '[]']\n",
      "Error decoding JSON in line: ['424', '0', '```json\\n{\\n    \"type\": [\"people.person\"]\\n}\\n```  ', '[]']\n",
      "Error decoding JSON in line: ['424', '1', '```json\\n{\\n    \"type\": [\"location.country\"]\\n}\\n```   ', \"['France', 'Spain', 'Belgium', 'Spain', 'Belgium']\"]\n",
      "Error decoding JSON in line: ['424', '2', '```json\\n{\\n    \"type\": [\"time.event\"]\\n}\\n```', '[]']\n",
      "Error decoding JSON in line: ['565', '0', \"Based on the entities in the first column of the table provided, the chosen valid type from the given list of types is `'location.island'`.\\n\\nHere is the answer in valid JSON format:\\n```\", '[]']\n",
      "Error decoding JSON in line: ['750', '0', \"Based on the entities mentioned in the first column of the table, the most suitable valid type from the given list is 'sports.rally_driver'. \\n\\nHere is the answer in valid JSON format:\\n{\\n\", '[]']\n",
      "Error decoding JSON in line: ['1038', '0', '```json\\n{\\n    \"type\": [\"location.citytown\"]\\n}\\n```  ', '[]']\n",
      "Error decoding JSON in line: ['1038', '1', '```json\\n{\\n    \"type\": [\"royalty.noble_person\"]\\n}\\n```', '[]']\n",
      "Error decoding JSON in line: ['1380', '0', '\\'\\'\\'\\n{\\n    \"type\": [\"people.person\"]\\n}\\n\\'\\'\\'  ', '[]']\n",
      "Error decoding JSON in line: ['1380', '1', '\\'\\'\\'\\n{\\n    \"type\": [\"location.country\"]\\n}\\n\\'\\'\\'', \"['Spain']\"]\n",
      "Error decoding JSON in line: ['1380', '2', '\\'\\'\\'\\n{\\n    \"type\": [\"time.event\"]\\n}\\n\\'\\'\\'', \"['1989', '1973', '1963']\"]\n",
      "Error decoding JSON in line: ['1507', '0', '```json\\n{\\n    \"type\": [\"time.event\"]\\n}\\n```', \"['2013', '2012', '2011', '2010', '2009']\"]\n",
      "Error decoding JSON in line: ['1507', '1', '```json\\n{\\n    \"type\": [\"people.person\"]\\n}\\n```', '[]']\n",
      "Error decoding JSON in line: ['1507', '2', '```json\\n{\\n    \"type\": [\"sports.sports_league\"]\\n}\\n```', '[]']\n",
      "Error decoding JSON in line: ['1507', '3', '```json\\n{\\n    \"type\": [\"location.location\"]\\n}\\n```', '[]']\n",
      "Error decoding JSON in line: ['1694', '0', 'Based on the entities in the first column of the given table, the most suitable type from the list would be \"location.citytown\".\\n\\n```json\\n{\\n  \"type\": [\"location.citytown\"]\\n', '[]']\n",
      "Error decoding JSON in line: ['1694', '1', 'Based on the entities in the second column of the given table, the most suitable type from the list would be \"location.citytown\".\\n\\n```json\\n{\\n  \"type\": [\"location.citytown\"]\\n', '[]']\n",
      "Error decoding JSON in line: ['1694', '2', 'Based on the entities in the third column of the given table, the most suitable type from the list would be \"location.state\".\\n\\n```json\\n{\\n  \"type\": [\"location.state\"]\\n}\\n```', '[]']\n",
      "Error decoding JSON in line: ['1694', '3', 'Based on the entities in the fourth column of the given table, the most suitable type from the list would be \"people.person\".\\n\\n```json\\n{\\n  \"type\": [\"people.person\"]\\n}\\n```', '[]']\n",
      "Error decoding JSON in line: ['1754', '0', \"Based on the provided entities in the first column:\\n\\nEntities: ['1998', '2000', '2004', '2010', '2011']\\n\\nI have chosen the valid type 'time\", \"['1998', '2000', '2004', '2010', '2011']\"]\n",
      "Error decoding JSON in line: ['1754', '1', 'Since the data in the 2nd column was not provided, could you please provide the entities present in the 2nd column of the table so that I can choose a valid type from the list', '[]']\n",
      "Error decoding JSON in line: ['1754', '2', 'As the data from the 3rd column was not provided, could you share the entities from the 3rd column so that I can select a valid type from the list provided earlier.', '[]']\n",
      "Error decoding JSON in line: ['1754', '3', 'Based on the given entity in the 4th column (\\'artificial satellite\\'), I have chosen the valid type \\'astronomy.celestial_object\\'.\\n\\nJSON Format:\\n```json\\n{\\n    \"type', \"['artificial satellite']\"]\n",
      "Error decoding JSON in line: ['2565', '0', \"Based on the provided entities in the first column:\\n```\\n['BaÅ¡kimi', 'Vlazrimi', 'Pobeda Valandovo', 'Sloga Jugomagn\", \"['FK Vlazrimi', 'Socialist Republic of Macedonia', 'locomotive', 'Gostivar', 'Prespa']\"]\n",
      "Error decoding JSON in line: ['2655', '0', \"Based on the entities in the first column of the table, the most suitable type from the given list of types is 'sports.sports_team'.\\n\\nHere is the answer in valid JSON format:\\n```json\", '[]']\n",
      "Error decoding JSON in line: ['2655', '1', \"Based on the entities in the second column of the table, the most suitable type from the given list of types is 'location.citytown'.\\n\\nHere is the answer in valid JSON format:\\n```json\\n\", '[]']\n",
      "Error decoding JSON in line: ['2655', '2', \"Based on the entities in the third column of the table, the most suitable type from the given list of types is 'architecture.structure'.\\n\\nHere is the answer in valid JSON format:\\n```json\\n{\\n\", '[]']\n",
      "Error decoding JSON in line: ['2929', '0', \"Based on the provided entities in the first column:\\n\\n['2007', '2008', '2009', '2010', '2011']\\n\\nI have chosen the following type from the list of\", \"['2007', '2008', '2009', '2010', '2011']\"]\n",
      "Error decoding JSON in line: ['2929', '1', 'I will need the entities in the second column in order to choose a valid type. Please provide the entities in the second column so that I can proceed with selecting a type from the list.', '[]']\n",
      "Error decoding JSON in line: ['2929', '2', 'I will need the entities in the third column in order to choose a valid type. Please provide the entities in the third column so that I can proceed with selecting a type from the list.', '[]']\n",
      "Error decoding JSON in line: ['3319', '0', 'Based on the entities in the first column of the table, the most appropriate type from the given list of types for the entities would be \"people.person\".\\n\\nTherefore, the answer in valid JSON format is', '[]']\n",
      "Error decoding JSON in line: ['3319', '1', 'Based on the entities in the second column of the table, the most appropriate type from the given list of types for the entities would be \"chemistry.chemical_compound\".\\n\\nTherefore, the answer in valid', \"['gram per femtolitre', 'gram per femtolitre', 'carbon', 'carbon', 'F/Cl-exchange on AlCl(3)-pyridine adducts: synthesis and characterization of trans-difluoro-tetrakis-pyridine-aluminum-chloride, [AlF2(Py)4]+Cl-.']\"]\n",
      "Error decoding JSON in line: ['3985', '0', \"Based on the given entities in the first column: ['quarterback', 'fullback', 'center'], we can assign the following type from the list of valid types: 'american_football.football\", \"['quarterback', 'fullback', 'center']\"]\n",
      "Error decoding JSON in line: ['4453', '0', \"Based on the provided entities in the first column:\\n\\nEntities: ['2013', '2012', '2011', '2010', '2009']\\n\\nAfter understanding the entities, a valid type\", \"['2013', '2012', '2011', '2010', '2009']\"]\n",
      "Error decoding JSON in line: ['4453', '1', 'I can help with that. Please provide me with the entities or values present in the second column of the table so that I can proceed with understanding the entities and selecting a valid type from the list.', '[]']\n",
      "Error decoding JSON in line: ['4453', '2', \"I'd be happy to help! Please provide me with the entities or values present in the third column of the table so that I can proceed with understanding the entities and selecting a valid type from the list\", '[]']\n",
      "Error decoding JSON in line: ['4453', '3', \"I'm here to assist with that. Kindly provide me with the entities or values present in the fourth column of the table so that I can proceed with understanding the entities and selecting a valid type from\", '[]']\n",
      "Error decoding JSON in line: ['4453', '4', \"I'm ready to assist with that. Please provide me with the entities or values present in the fifth column of the table so that I can proceed with understanding the entities and selecting a valid type from the\", '[]']\n",
      "Error decoding JSON in line: ['4453', '5', 'I can assist with that. Please provide me with the entities or values present in the sixth column of the table so that I can proceed with understanding the entities and selecting a valid type from the list.', '[]']\n",
      "len(preds):  13025\n",
      "0.6713409290096407\n",
      "874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2001247/461137969.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  class_p = conf_mat[:, 1, 1] /  conf_mat[:, 1, :].sum(axis=1)\n",
      "/tmp/ipykernel_2001247/461137969.py:28: RuntimeWarning: invalid value encountered in divide\n",
      "  class_r = conf_mat[:, 1, 1] /  conf_mat[:, :, 1].sum(axis=1)\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "label_dir = '/mmfs1/gscratch/balazinska/linxiwei/TURL/Baseline-TURL/sample_labels.txt'\n",
    "with open(label_dir, 'r') as file:\n",
    "    labels = file.readlines()\n",
    "labels = [line.strip() for line in labels]\n",
    "pred_dir = ''\n",
    "micro_f1, macro_f1, class_f1, conf_mat, num_oov, hints = single_label_eval(pred_dir, labels)\n",
    "print(micro_f1)\n",
    "print(num_oov)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
