{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "import tqdm\n",
    "from utils import *\n",
    "from type_vocabs import *\n",
    "import tiktoken\n",
    "enc = tiktoken.encoding_for_model(\"gpt-3.5-turbo-0125\")\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize(types):\n",
    "    cnt = 0\n",
    "    result = {}\n",
    "    for type in type_vocab:\n",
    "        result[type] = 0\n",
    "    for item in types:\n",
    "        if item in result:\n",
    "            result[item] = 1\n",
    "        else: \n",
    "            cnt += 1\n",
    "\n",
    "    return result, cnt\n",
    "\n",
    "def f1_score_multilabel(true_list, pred_list, types_label=None):\n",
    "    if types_label is not None:\n",
    "        conf_mat = multilabel_confusion_matrix(np.array(true_list),\n",
    "                                           np.array(pred_list),labels=types_label)\n",
    "    else: conf_mat = multilabel_confusion_matrix(np.array(true_list),\n",
    "                                           np.array(pred_list))\n",
    "    agg_conf_mat = conf_mat.sum(axis=0)\n",
    "    # Note: Pos F1\n",
    "    # [[TN FP], [FN, TP]] if we consider 1 as the positive class\n",
    "    p = agg_conf_mat[1, 1] / agg_conf_mat[1, :].sum()\n",
    "    r = agg_conf_mat[1, 1] / agg_conf_mat[:, 1].sum()\n",
    "    \n",
    "    micro_f1 = 2 * p * r / (p  + r) if (p + r) > 0 else 0.\n",
    "    class_p = conf_mat[:, 1, 1] /  conf_mat[:, 1, :].sum(axis=1)\n",
    "    class_r = conf_mat[:, 1, 1] /  conf_mat[:, :, 1].sum(axis=1)\n",
    "    class_f1 = np.divide(2 * (class_p * class_r), class_p + class_r,\n",
    "                         out=np.zeros_like(class_p), where=(class_p + class_r) != 0)\n",
    "    class_f1 = np.nan_to_num(class_f1)\n",
    "    macro_f1 = class_f1.mean()\n",
    "    return (micro_f1, macro_f1, class_f1, conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sotab_eval(data_dir, labels, type_vocab, col_pairs=None, is_triplet=False, correct=False):\n",
    "    preds = []\n",
    "    ground_truth = []\n",
    "    num_oov = 0\n",
    "    hints = []\n",
    "    with open(data_dir, mode ='r') as file:\n",
    "        csvFile = csv.reader(file)\n",
    "        for id, lines in enumerate(csvFile):\n",
    "                num = lines[0]\n",
    "                idx = lines[1]\n",
    "                label = labels[id]\n",
    "                ground_truth.append(str(label))\n",
    "                hint = \"\"\n",
    "                if len(lines) <= 2:\n",
    "                    preds.append(\"\")\n",
    "                    hints.append(\"\")\n",
    "                    continue\n",
    "                if len(lines) >= 4:\n",
    "                    hint = lines[3]\n",
    "                # if hint is not None and is_triplet: \n",
    "                #     hint = hint.split(\":\", 1)[1].strip()\n",
    "                hints.append(hint)\n",
    "                \n",
    "                try:\n",
    "                    data = json.loads(lines[2].replace(\"'\", '\"'))\n",
    "                    type_value = data.get('relation', [])\n",
    "                    if isinstance(type_value, list) and len(type_value) > 0:\n",
    "                        type_value = type_value[0]\n",
    "                    preds.append(str(type_value))\n",
    "                    if type_value not in type_vocab:\n",
    "                        num_oov += 1\n",
    "                    if not correct and type_value != label:\n",
    "                        col_pairs.append((num,idx,type_value,label,hint))\n",
    "                    if correct and type_value == label:\n",
    "                        col_pairs.append((num,idx,type_value,label,hint))\n",
    "                except json.JSONDecodeError:\n",
    "                    preds.append(\"\")\n",
    "                    print(f\"Error decoding JSON in line: {lines}\")\n",
    "    print(\"len(preds): \", len(preds))\n",
    "    micro_f1, macro_f1, class_f1, conf_mat = f1_score_multilabel(ground_truth, preds, type_vocab)\n",
    "    return micro_f1, macro_f1, class_f1, conf_mat, num_oov, hints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_label_eval(data_dir, labels, wrong_col_pairs = None, decode_ok=0):\n",
    "    preds = []\n",
    "    ground_truth = []\n",
    "    empty = serialize([])[0].values()\n",
    "    empty = [*empty]\n",
    "    num_oov = 0\n",
    "    with open(data_dir, mode ='r') as file:\n",
    "        csvFile = csv.reader(file)\n",
    "        for id, lines in enumerate(csvFile):\n",
    "                pred = []\n",
    "                if len(lines) <= 2:\n",
    "                    preds.append(empty)\n",
    "                    continue\n",
    "                try:\n",
    "                    num = lines[0]\n",
    "                    idx = lines[1]\n",
    "                    data = json.loads(data.replace(\"'\", '\"'))\n",
    "                    type_value = data.get('type', [])\n",
    "                    label = labels[id]\n",
    "                    pred_dic, cnt = serialize(type_value)\n",
    "                    num_oov += cnt\n",
    "                    pred = pred_dic.values()\n",
    "                    pred = [*pred]\n",
    "                    preds.append(pred)\n",
    "                    decode_ok += 1\n",
    "                    if len(type_value) > 0 and type_value[0] in label:\n",
    "                        gt = pred\n",
    "                    else:\n",
    "                        gt = serialize(label)[0].values()\n",
    "                        gt = [*gt]\n",
    "                        if wrong_col_pairs is not None: \n",
    "                            wrong_col_pairs.append((num,idx,type_value ,label))\n",
    "\n",
    "                except json.JSONDecodeError:\n",
    "                    \n",
    "                    preds.append(empty)\n",
    "                    label = labels[id]\n",
    "                    gt = serialize(label)[0].values()\n",
    "                    gt = [*gt]\n",
    "                    print(f\"Error decoding JSON in line: {lines}\")\n",
    "                ground_truth.append(gt)\n",
    "    print(\"len(preds): \", len(preds))\n",
    "    micro_f1, macro_f1, class_f1, conf_mat = f1_score_multilabel(ground_truth, preds)\n",
    "    return micro_f1, macro_f1, class_f1, conf_mat, num_oov, decode_ok\n",
    "\n",
    "def multi_label_eval(data_dir, labels):\n",
    "    ground_truth = []\n",
    "    for label in labels:\n",
    "        label = ast.literal_eval(label)\n",
    "        gt = serialize(label).values()\n",
    "        gt = [*gt]\n",
    "        ground_truth.append(gt)\n",
    "    preds = []\n",
    "    empty = serialize([])[0].values()\n",
    "    empty = [*empty]\n",
    "    with open(data_dir, mode ='r') as file:\n",
    "        csvFile = csv.reader(file)\n",
    "        for lines in csvFile:\n",
    "                pred = []\n",
    "                if len(lines) <= 2:\n",
    "                    preds.append(empty)\n",
    "                    continue\n",
    "                try:\n",
    "                    data = json.loads(lines[2].replace(\"'\", '\"'))\n",
    "                    type_value = data.get('type', [])\n",
    "                    pred = serialize(type_value).values()\n",
    "                    pred = [*pred]\n",
    "                    preds.append(pred)\n",
    "                except json.JSONDecodeError:\n",
    "                    preds.append(empty)\n",
    "    \n",
    "    micro_f1, macro_f1, class_f1, conf_mat = f1_score_multilabel(ground_truth, preds)\n",
    "    return micro_f1, macro_f1, class_f1, conf_mat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "label_dir = ''\n",
    "with open(label_dir, 'r') as file:\n",
    "    labels = file.readlines()\n",
    "labels = [line.strip() for line in labels]\n",
    "wrong_col_pairs_etl = []\n",
    "pred_dir = ''\n",
    "micro_f1, macro_f1, class_f1, conf_mat, num_oov, hints = sotab_eval(pred_dir, labels, SOTAB_CPA_type_vocab, wrong_col_pairs_etl)\n",
    "print(micro_f1)\n",
    "print(num_oov)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
